





import matplotlib.pyplot as plt
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential



import wandb
from wandb.integration.keras import WandbMetricsLogger
from wandb.integration.keras import WandbModelCheckpoint
from wandb.integration.keras import WandbEvalCallback





# Define a dictionary named configs with various configuration settings for the model
configs = dict(
    # Set the number of classes to 1 (e.g., for binary classification)
    num_classes = 1,
    
    # Set the batch size to 32 (number of samples per gradient update)
    batch_size = 32,
    
    # Set the image size to 224 (both width and height, assuming square images)
    image_size = 224,
    
    # Set the number of image channels to 3 (e.g., for RGB images)
    image_channels = 3,
    
    # Set the patience for early stopping to 3 (number of epochs with no improvement after which training will be stopped)
    earlystopping_patience = 3,
    
    # Set the learning rate for the optimizer to 1e-3 (0.001)
    learning_rate = 1e-3,
    
    # Set the initial number of epochs for training to 8
    initial_epochs = 8
)






# Define a function to load data from directories
def load_data(train_dir, val_dir, test_dir, IMG_SIZE, BATCH_SIZE):
    # Load the training dataset from the specified directory, shuffling the data and setting the batch size and image size
    train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,
                                                                shuffle=True,
                                                                batch_size=BATCH_SIZE,
                                                                image_size=IMG_SIZE)
    # Load the validation dataset from the specified directory, shuffling the data and setting the batch size and image size
    validation_dataset = tf.keras.utils.image_dataset_from_directory(val_dir,
                                                                     shuffle=True,
                                                                     batch_size=BATCH_SIZE,
                                                                     image_size=IMG_SIZE)
    # Load the test dataset from the specified directory, setting the batch size and image size (no shuffling)
    test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,
                                                               batch_size=BATCH_SIZE,
                                                               image_size=IMG_SIZE)
    # Return the loaded datasets
    return train_dataset, validation_dataset, test_dataset

# Extract the batch size from the configs dictionary
BATCH_SIZE = configs["batch_size"]
# Extract the image size from the configs dictionary and convert it to a tuple
IMG_SIZE = (configs["image_size"], configs["image_size"])

# Define the directory path for the training dataset
train_directory = '/home/arsalan/DATA/github_files/keras_cv/TyreQualityPrediction/dataset/train'
# Define the directory path for the validation dataset
valid_directory = '/home/arsalan/DATA/github_files/keras_cv/TyreQualityPrediction/dataset/valid'
# Define the directory path for the test dataset
test_directory = '/home/arsalan/DATA/github_files/keras_cv/TyreQualityPrediction/dataset/test'

# Call the load_data function with the specified directories, image size, and batch size
# Store the returned datasets in train_dataset, validation_dataset, and test_dataset variables
train_dataset, validation_dataset, test_dataset = load_data(train_directory, valid_directory, test_directory, IMG_SIZE, BATCH_SIZE)






# Extract the class names from the train dataset and store them in the variable train_dataset_class_names
train_dataset_class_names = train_dataset.class_names

# Extract the class names from the test dataset and store them in the variable test_dataset_class_names
test_dataset_class_names = test_dataset.class_names

# Extract the class names from the validation dataset and store them in the variable validation_dataset_class_names
validation_dataset_class_names = validation_dataset.class_names

# Print the class names from the train dataset
print(f"Class names in train dataset: {train_dataset_class_names}")

# Print the class names from the test dataset
print(f"Class names in test dataset: {test_dataset_class_names}")

# Print the class names from the validation dataset
print(f"Class names in validation dataset: {validation_dataset_class_names}")






# Define the project name for wandb
PROJECT = "Vehicle-Tyres-Health-Condition-Classification"
# Define the team name for wandb
TEAM = "teamarsalan"


# Define a function to add raw data to a Weights and Biases (wandb) table
def addRawdata(dataset):
    # Initialize a wandb Table with columns "Images" and "label"
    table = wandb.Table(columns=["Images", "label"])
    
    # Iterate over the dataset, which contains batches of images and labels
    for images, labels in dataset:
        # Iterate over each image and label in the current batch
        for i in range(images.shape[0]):
            # Get the i-th image from the current batch
            image = images[i]
            # Get the i-th label from the current batch
            label = labels[i]
            # Add the image and label to the table
            table.add_data(wandb.Image(image), label)
    
    # Return the populated table
    return table



#Upload train raw dataset to wandb
# Initialize a new wandb run with the specified project and team names, and set the job type to "upload"
run = wandb.init(project=PROJECT, entity=TEAM, job_type="upload")
# Create a new wandb Artifact named "Train_raw_data" with the type "raw_data"
raw_data_at = wandb.Artifact("Train_raw_data", type="raw_data")
# Add the directory "dataset/train" to the artifact under the name "Train_raw_data"
raw_data_at.add_dir(train_directory, name="Train_raw_data")

# Call the addRawdata function with the train_dataset and store the returned table in the variable table
table = addRawdata(train_dataset)
# Add the table to the artifact under the name "Train_raw_data"
raw_data_at.add(table, "Train_raw_data")

# Log the artifact to the current wandb run
run.log_artifact(raw_data_at)
# Finish the wandb run, ensuring all data is logged and the run is properly closed
run.finish()


# Upload Validation raw dataset to wandb
# Initialize a new wandb run with the specified project and team names, and set the job type to "upload"
run = wandb.init(project=PROJECT, entity=TEAM, job_type="upload")

# Create a new wandb Artifact named "Validation_raw_data" with the type "raw_data"
raw_data_at = wandb.Artifact("Validation_raw_data", type="raw_data")

# Add the directory specified by valid_directory to the artifact under the name "Validation_raw_data"
raw_data_at.add_dir(valid_directory, name="Validation_raw_data")

# Call the addRawdata function with the validation_dataset and store the returned table in the variable table
table = addRawdata(validation_dataset)

# Add the table to the artifact under the name "Validation_raw_data"
raw_data_at.add(table, "Validation_raw_data")

# Log the artifact to the current wandb run
run.log_artifact(raw_data_at)

# Finish the wandb run, ensuring all data is logged and the run is properly closed
run.finish()




# Upload Test raw dataset to wandb
# Initialize a new wandb run with the specified project and team names, and set the job type to "upload"
run = wandb.init(project=PROJECT, entity=TEAM, job_type="upload")

# Create a new wandb Artifact named "Test_raw_data" with the type "raw_data"
raw_data_at = wandb.Artifact("Test_raw_data", type="raw_data")

# Add the directory specified by test_directory to the artifact under the name "Test_raw_data"
raw_data_at.add_dir(test_directory, name="Test_raw_data")

# Call the addRawdata function with the test_dataset and store the returned table in the variable table
table = addRawdata(test_dataset)

# Add the table to the artifact under the name "Test_raw_data"
raw_data_at.add(table, "Test_raw_data")

# Log the artifact to the current wandb run
run.log_artifact(raw_data_at)

# Finish the wandb run, ensuring all data is logged and the run is properly closed
run.finish()







plt.figure(figsize=(10, 10))
for images, labels in train_dataset.take(1):
    print("Image batch shape:", images.shape)  
    print("Label batch shape:", labels.shape)
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        plt.imshow(images[i].numpy().astype("uint8"))
        plt.title(train_dataset_class_names[labels[i]])
        plt.axis("off")
        





def data_augmenter():
    '''
    Create a Sequential model composed of 2 layers
    Returns:
        tf.keras.Sequential
    '''
    data_augmentation = tf.keras.Sequential([
        tf.keras.layers.RandomFlip('horizontal'),
        tf.keras.layers.RandomRotation(0.2),
    ])
    return data_augmentation

# Initialize the data augmentation layer
augmentation_layer = data_augmenter()

# Define a function to apply the augmentation
def augment(image, label):
    image = augmentation_layer(image)
    return image, label




# Assume train_dataset, validation_dataset, and test_dataset are already defined
AUTOTUNE = tf.data.AUTOTUNE

# Apply the augmentation only to the training dataset
train_dataset = train_dataset.map(augment, num_parallel_calls=AUTOTUNE)
train_dataset = train_dataset.cache().prefetch(buffer_size=AUTOTUNE)

# The validation and test datasets do not need augmentation
validation_dataset = validation_dataset.cache().prefetch(buffer_size=AUTOTUNE)
test_dataset = test_dataset.cache().prefetch(buffer_size=AUTOTUNE)






data_augmentation = data_augmenter()

for image, _ in train_dataset.take(1):
    plt.figure(figsize=(10, 10))
    first_image = image[0]
    for i in range(9):
        ax = plt.subplot(3, 3, i + 1)
        augmented_image = data_augmentation(tf.expand_dims(first_image, 0))
        plt.imshow(augmented_image[0] / 255)
        plt.axis('off')
    





preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input
IMG_SHAPE = (configs["image_size"], configs["image_size"], configs["image_channels"])
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')


base_model.trainable = False
base_model.summary()


def model(inputshape, preprocess_input,base_model):
    # Define the input layer with the specified input shape
    inputs = tf.keras.Input(shape=inputshape)
    
    # Preprocess the inputs using the MobileNetV2 preprocessing function
    x = preprocess_input(inputs)
    
    # Pass the preprocessed inputs through the base model (MobileNetV2)
    x = base_model(x, training=False)
    
    # Apply global average pooling to reduce the spatial dimensions
    x = tf.keras.layers.GlobalAveragePooling2D()(x)
    
    # Apply a dropout layer with a 20% dropout rate for regularization
    x = tf.keras.layers.Dropout(0.2)(x)
    
    # Add a dense output layer with a single neuron and sigmoid activation function for binary classification
    outputs = tf.keras.layers.Dense(1, activation='sigmoid')(x)
    
    # Create the model by specifying the inputs and outputs
    model = tf.keras.Model(inputs, outputs)
    
    # Return the constructed model
    return model



# Create the model with the specified input shape and set the base model layers as non-trainable
model = model(IMG_SHAPE,preprocess_input,base_model)


model.summary()





callbacks = [
    # ModelCheckpoint callback saves the model after every epoch.
    # The filename includes the accuracy, validation accuracy, loss, and validation loss.
    tf.keras.callbacks.ModelCheckpoint(
        'model_accuracy:{accuracy:0.2f}_Val_acc:{val_accuracy:0.2f}_loss:{loss:0.2f}_Val_loss:{val_loss:0.2f}.keras', 
        save_best_only=True,  # Save only the best model based on the monitored metric.
        monitor='val_loss'  # Monitor the validation accuracy to determine the best model.
    ),
    # EarlyStopping callback stops training when the monitored metric has stopped improving.
    tf.keras.callbacks.EarlyStopping(
        monitor='val_loss',  # Monitor the validation accuracy.
        patience= 5,  # Number of epochs with no improvement after which training will be stopped.
        restore_best_weights=True  # Restore model weights from the epoch with the best value of the monitored metric.
    )
]


# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type="Training",
    config = configs
)



# corrected code 

class WandbClfEvalCallback(WandbEvalCallback):
    def __init__(self, validloader, data_table_columns, pred_table_columns, num_samples=100):
        super().__init__(data_table_columns, pred_table_columns)
        
        # Take a fixed number of samples from the validation loader, converting it to a list for fixed iteration
        self.val_data = list(validloader.unbatch().take(num_samples))
        self.data_table_columns = data_table_columns
        self.pred_table_columns = pred_table_columns

    def add_ground_truth(self, logs=None):
        # Iterate over the fixed number of samples in the validation data
        for idx, (image, label) in enumerate(self.val_data):
            # Add each image and its corresponding label to the data table
            self.data_table.add_data(idx, wandb.Image(image.numpy()), int(label.numpy()))

    def add_model_predictions(self, epoch, logs=None):
        # Get predictions for the validation samples
        preds = self._inference()
        table_idxs = range(len(self.val_data))

        # Add predictions to the prediction table along with corresponding ground truth data
        for idx in table_idxs:
            pred = preds[idx]
            self.pred_table.add_data(
                epoch,
                idx,
                self.data_table.data[idx][1],  # Image
                self.data_table.data[idx][2],  # Ground truth label
                pred,  # Predicted label
            )

    def _inference(self):
        preds = []
        # Iterate over the fixed number of samples in the validation data
        for image, label in self.val_data:
            # Get model prediction for each image
            pred = self.model(tf.expand_dims(image, axis=0))
            binary_pred = (pred.numpy() > 0.5).astype(int)[0][0]
            preds.append(binary_pred)
        return preds



def compile_model(model, learning_rate):
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=tf.keras.losses.BinaryCrossentropy(),
                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])

                  
def fit_model(model, train_dataset, validation_dataset, initial_epochs , callbacks):                  
    history = model.fit(train_dataset, validation_data=validation_dataset, epochs=initial_epochs, 
                        callbacks= callbacks 
                       )
    return history





callbacks=[callbacks,
           WandbMetricsLogger(log_freq=10),
           WandbClfEvalCallback(
               validation_dataset,
               data_table_columns=["idx", "image", "ground_truth"],
               pred_table_columns=["epoch", "idx", "image", "ground_truth", "prediction"],
           ),
          ]
learning_rate = configs["learning_rate"]
initial_epochs = 10
compile_model(model, learning_rate)
history = fit_model(model, train_dataset, validation_dataset, initial_epochs ,callbacks)


wandb.finish()





def plot_history(history):
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy / Loss')
    plt.legend(loc='lower right')
    plt.show()

plot_history(history)


def plot_history(history):
    acc = history.history['accuracy']
    val_acc = history.history['val_accuracy']
    
    loss = history.history['loss']
    val_loss = history.history['val_loss']
    
    plt.figure(figsize=(8, 8))
    plt.subplot(2, 1, 1)
    plt.plot(acc, label='Training Accuracy')
    plt.plot(val_acc, label='Validation Accuracy')
    plt.legend(loc='lower right')
    plt.ylabel('Accuracy')
    plt.ylim([min(plt.ylim()),1])
    plt.title('Training and Validation Accuracy')
    
    plt.subplot(2, 1, 2)
    plt.plot(loss, label='Training Loss')
    plt.plot(val_loss, label='Validation Loss')
    plt.legend(loc='upper right')
    plt.ylabel('Cross Entropy')
    plt.ylim([0,1.0])
    plt.title('Training and Validation Loss')
    plt.xlabel('epoch')
    plt.show()
    return acc ,val_acc,loss,val_loss

acc ,val_acc,loss,val_loss = plot_history(history)








base_model.trainable = True
# Let's take a look to see how many layers are in the base model
print("Number of layers in the base model: ", len(base_model.layers))





# Fine-tune from this layer onwards
fine_tune_at = 100

# Freeze all the layers before the `fine_tune_at` layer
for layer in base_model.layers[:fine_tune_at]:
  layer.trainable = False


model = model(IMG_SHAPE,preprocess_input,base_model)
model.summary()






# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type = "Fine Tuning phase 2",
    config = configs
)



earning_rate = 1e-5
initial_epochs = 10
compile_model(model, learning_rate)


# Define the number of epochs for fine-tuning
fine_tune_epochs = 15  # Number of epochs for fine-tuning after initial training

# Calculate the total number of epochs for the entire training process
total_epochs = initial_epochs + fine_tune_epochs

# Define a function to fit the model with fine-tuning
def fit_model_finetune(train_dataset, validation_dataset, initial_epochs, total_epochs, callbacks):
    # Fit the model using the training dataset
    # Start training from the last completed epoch in the initial training phase
    fine_tune_history = model.fit(
        train_dataset,
        epochs=total_epochs,  # Train until the total number of epochs is reached
        initial_epoch=len(history.epoch),  # Continue training from the epoch where initial training stopped
        validation_data=validation_dataset,  # Use the validation dataset for validation
        callbacks=callbacks  # Use the specified callbacks for saving the model and early stopping
    )
    return fine_tune_history  # Return the training history of the fine-tuning phase

# Perform fine-tuning on the model using the training and validation datasets
fine_tune_history = fit_model_finetune(train_dataset, validation_dataset, initial_epochs, total_epochs, callbacks)



wandb.finish()


def plot_history(history):
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy / Loss')
    plt.legend(loc='lower right')
    plt.show()

plot_history(fine_tune_history)


acc += fine_tune_history.history['accuracy']
val_acc += fine_tune_history.history['val_accuracy']

loss += fine_tune_history.history['loss']
val_loss += fine_tune_history.history['val_loss']


plt.figure(figsize=(8, 8))
plt.subplot(2, 1, 1)
plt.plot(acc, label='Training Accuracy')
plt.plot(val_acc, label='Validation Accuracy')
plt.ylim([0.8, 1])
plt.plot([initial_epochs-1,initial_epochs-1],
          plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(2, 1, 2)
plt.plot(loss, label='Training Loss')
plt.plot(val_loss, label='Validation Loss')
plt.ylim([0, 1.0])
plt.plot([initial_epochs-1,initial_epochs-1],
         plt.ylim(), label='Start Fine Tuning')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.xlabel('epoch')
plt.show()





base_model.trainable = False 


from tensorflow.keras.models import load_model



model_path = 'model_accuracy:0.94_Val_acc:0.93_loss:0.16_Val_loss:0.17.keras'


loaded_best_model = load_model(model_path)


wandb.finish()


# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type="Initial model's further Training",
    config = configs
)


def compile_model(model, learning_rate):
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),
                  loss=tf.keras.losses.BinaryCrossentropy(),
                  metrics=[tf.keras.metrics.BinaryAccuracy(threshold=0.5, name='accuracy')])

                  
def fit_model(model, train_dataset, validation_dataset, initial_epochs , callbacks):                  
    history = model.fit(train_dataset, validation_data=validation_dataset, epochs=initial_epochs, 
                        callbacks= callbacks 
                       )
    return history



callbacks=[callbacks,
           WandbMetricsLogger(log_freq=10),
           WandbClfEvalCallback(
               validation_dataset,
               data_table_columns=["idx", "image", "ground_truth"],
               pred_table_columns=["epoch", "idx", "image", "ground_truth", "prediction"],
           ),
          ]
learning_rate = 1e-6 # setting much smaller learning rate for better convergence
initial_epochs = 10
compile_model(loaded_best_model, learning_rate)
loaded_model_history = fit_model(loaded_best_model, train_dataset, validation_dataset, initial_epochs ,callbacks)


wandb.finish()


def plot_history(history):
    plt.plot(history.history['accuracy'], label='accuracy')
    plt.plot(history.history['val_accuracy'], label='val_accuracy')
    plt.plot(history.history['loss'], label='loss')
    plt.plot(history.history['val_loss'], label='val_loss')
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy / Loss')
    plt.legend(loc='lower right')
    plt.show()

plot_history(loaded_model_history)





# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type = "Evaluation Log accuracy and loss",
    config = configs
)



model_path = 'model_accuracy:0.94_Val_acc:0.93_loss:0.16_Val_loss:0.17.keras'
loaded_best_model = load_model(model_path)


loss, accuracy = loaded_best_model.evaluate(test_dataset)
print('Test accuracy :', accuracy )
print("Test loss :" ,loss)
wandb.log({"Test accuracy":accuracy , "Test loss":loss})


wandb.finish()





# Retrieve a batch of images from the test set
image_batch, label_batch = test_dataset.as_numpy_iterator().next()
predictions = model.predict_on_batch(image_batch).flatten()
predictions = tf.where(predictions < 0.5, 0, 1)

print('Predictions:\n', predictions.numpy())
print('Labels:\n', label_batch)




# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type = "Predictions image",
    config = configs
)


plt.figure(figsize=(10, 10))
for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(image_batch[i].astype("uint8"))
    plt.title(test_dataset_class_names[predictions[i]])
    plt.axis("off")
wandb.log({"img":[wandb.Image(plt,caption="Predictions on a batch")]})
    


wandb.finish()


from sklearn.metrics import confusion_matrix , classification_report
import seaborn as sns


# Initialize lists to accumulate predictions and labels
all_predictions = []
all_labels = []

# Iterate through the dataset
for image_batch, label_batch in test_dataset:
    predictions = model.predict_on_batch(image_batch).flatten()
    predictions = tf.where(predictions < 0.5, 0, 1)
    
    # Append current batch predictions and labels to the lists
    all_predictions.extend(predictions.numpy())
    all_labels.extend(label_batch.numpy())

# Convert lists to numpy arrays
all_predictions = np.array(all_predictions)
all_labels = np.array(all_labels)

# Print or visualize predictions and labels
print('All Predictions:\n', all_predictions)
print('All Labels:\n', all_labels)



len(all_predictions),len(all_labels)


type(all_predictions)


cm = confusion_matrix(all_labels, all_predictions)
cm


# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type = "Confusion matrix image",
    config = configs
)


# Plot confusion matrix with annotations for all values
plt.figure(figsize=(8, 8))
ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Greens', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Add annotations for correct classifications
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=8)
wandb.log({"img":[wandb.Image(plt,caption="Confusion Matrix")]})
plt.show()


wandb.finish()


# Initialize a W&B run
wandb.init(
    project = PROJECT,
    job_type = "Class classification logs",
    config = configs
)


#Calculate and print accuracy for each class
class_accuracies = cm.diagonal() / cm.sum(axis=1)
for i, accuracy in enumerate(class_accuracies):
    print(f'Accuracy for class {i}: {accuracy:.2f}')
    wandb.log({f"{i}": str(accuracy)})
    


wandb.finish()


# Print classification report
print("Classification Report:")
calssification_report = classification_report(all_labels, all_predictions )


type(calssification_report)


print(calssification_report)







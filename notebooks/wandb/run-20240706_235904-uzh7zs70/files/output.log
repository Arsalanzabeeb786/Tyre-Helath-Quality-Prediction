2024-07-06 23:59:44.639834: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.
2024-07-06 23:59:44.640121: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence
[34m[1mwandb[39m[22m:   101 of 101 files downloaded.
Epoch 1/10
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1720278002.830413   92329 service.cc:145] XLA service 0xa3c4b90 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
I0000 00:00:1720278002.830497   92329 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce GTX 1650, Compute Capability 7.5
2024-07-07 00:00:03.135511: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2024-07-07 00:00:03.939248: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907
[1m 14/138[22m [32m━━[37m━━━━━━━━━━━━━━━━━━[39m [1m9s[22m 75ms/step - accuracy: 0.6088 - loss: 0.6430
I0000 00:00:1720278012.167626   92329 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.





[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m55s[22m 294ms/step - accuracy: 0.7634 - loss: 0.4631 - val_accuracy: 0.9141 - val_loss: 0.2199
Epoch 2/10
[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 162ms/step - accuracy: 0.8904 - loss: 0.2607 - val_accuracy: 0.9387 - val_loss: 0.1907
Epoch 3/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 161ms/step - accuracy: 0.9057 - loss: 0.2228 - val_accuracy: 0.9387 - val_loss: 0.1791
Epoch 4/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 163ms/step - accuracy: 0.9191 - loss: 0.1946 - val_accuracy: 0.9325 - val_loss: 0.1736
Epoch 5/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 163ms/step - accuracy: 0.9257 - loss: 0.1803 - val_accuracy: 0.9387 - val_loss: 0.1747
Epoch 6/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m23s[22m 166ms/step - accuracy: 0.9357 - loss: 0.1672 - val_accuracy: 0.9387 - val_loss: 0.1590
Epoch 7/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 159ms/step - accuracy: 0.9410 - loss: 0.1540 - val_accuracy: 0.9387 - val_loss: 0.1637
Epoch 8/10


[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m23s[22m 164ms/step - accuracy: 0.9458 - loss: 0.1433 - val_accuracy: 0.9448 - val_loss: 0.1595
Epoch 9/10



[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m22s[22m 160ms/step - accuracy: 0.9484 - loss: 0.1370 - val_accuracy: 0.9325 - val_loss: 0.1586
Epoch 10/10



[1m138/138[22m [32m━━━━━━━━━━━━━━━━━━━━[39m [1m21s[22m 156ms/step - accuracy: 0.9448 - loss: 0.1371 - val_accuracy: 0.9387 - val_loss: 0.1604
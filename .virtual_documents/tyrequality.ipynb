import tensorflow as tf 
import keras
import keras_cv
import keras_core
from keras import losses , metrics 
import numpy as np 
import matplotlib.pyplot as plt 


train_ds  = tf.keras.utils.image_dataset_from_directory (
    "dataset/train",
    labels="inferred",
    color_mode="rgb",
    batch_size=32,
    image_size = (256,256),
    shuffle=True,
    seed =123,
    verbose=True
)


val_ds = tf.keras.utils.image_dataset_from_directory (
    "dataset/valid",
    labels="inferred",
    color_mode="rgb",
    batch_size=32,
    image_size = (256,256),
    seed =123,
    verbose=True
)


test_ds = tf.keras.utils.image_dataset_from_directory (
    "dataset/test",
    labels="inferred",
    color_mode="rgb",
    batch_size=32,
    image_size = (256,256),
    seed =123,
    verbose=True
)


train_ds 


class_names = train_ds.class_names
print(class_names)


plt.figure(figsize=(15, 15))
for images, labels in train_ds.take(1):
  for i in range(9):
    ax = plt.subplot(3, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(class_names[labels[i]])
    plt.axis("off")


image = next(iter(train_ds.take(1)))[0]
image.shape


model = keras_cv.models.ImageClassifier.from_preset(

    "efficientnetv2_b0_imagenet",
    num_classes = 2
)


model.compile(

    loss = "sparse_categorical_crossentropy",
    optimizer = tf.keras.optimizers.AdamW(),
    metrics = ["accuracy"]
)


model_history = model.fit(

    train_ds,
    validation_data = val_ds,
    epochs = 5,   
)


plt.plot(model_history.history["loss"],label="loss")
plt.plot(model_history.history["val_loss"],label="val_loss")
plt.legend()


plt.plot(model_history.history["accuracy"],label="accuracy")
plt.plot(model_history.history["val_accuracy"],label="val_accuracy")
plt.legend()


model.save("model_accuracy_0.9929_loss_0.0268_val_accuracy_0.9968_val_loss_0.0094.h5")


model.save('my_model.keras')


model.summary(show_trainable = True)


from keras.models import load_model
loaded_model = load_model('my_model.keras')



loaded_model.summary(show_trainable = True)



# Initialize an empty list to store labels
y_true = []

# Iterate over the validation dataset
for _, labels in test_ds:
    y_true.extend(labels.numpy())  # Convert labels to a NumPy array and extend the list

# Convert the list of labels to a NumPy array
y_true = np.array(y_true)

# Now 'all_labels_array' contains all the labels from the validation dataset
print(y_true), print(len(y_true))



from sklearn.metrics import confusion_matrix , classification_report
import seaborn as sns


predict = loaded_model.predict(test_ds)


predict.shape,len(predict)/32


print(np.argmax(predict , axis = 1))


val_ds.class_names


y_predict = np.argmax(predict , axis = 1)


y_predict


from sklearn.metrics import confusion_matrix , classification_report
cm = confusion_matrix(y_true, y_predict)



# Plot confusion matrix with annotations for all values
plt.figure(figsize=(8, 8))
ax = sns.heatmap(cm, annot=False, fmt='d', cmap='Greens', cbar=False)
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')

# Add annotations for correct classifications
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        ax.text(j + 0.5, i + 0.5, f'{cm[i, j]}', ha='center', va='center', color='black', fontsize=8)

plt.show()


# Calculate and print accuracy for each class
class_accuracies = cm.diagonal() / cm.sum(axis=1)
for i, accuracy in enumerate(class_accuracies):
    print(f'Accuracy for class {i}: {accuracy:.2f}')


# Print classification report
print("Classification Report:")
print(classification_report(y_true, y_predict))



print(f"Predcited : {y_predict[8]} and ground true label was :{y_true[8]} ")


plt.figure(figsize=(15, 15))
for images, labels in test_ds:
  for i in range(30):
    ax = plt.subplot(10, 3, i + 1)
    plt.imshow(images[i].numpy().astype("uint8"))
    plt.title(f"Actual label {labels[i]} / Predicted label {y_predict[i]}")
    plt.axis("off")


result = np.absolute(y_true - y_predict)


result



